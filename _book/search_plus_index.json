{"./":{"url":"./","title":"Introduction","keywords":"","body":"集美大学无人机科创实验室 集美大学无人机实验室成立于2020年，专注于研究、开发和无人机相关技术，致力于推动无人机领域的创新和发展。 我们由来自电子信息工程、通信工程、人工智能、微电子科学与工程等专业的同学和老师而组成，共同合作，进行无人机等涵盖无人机、机器人、视频编解码、深度学习等领域的研究和项目开发。 我们的主要目标之一是锻炼培养在无人机技术等相关领域的能力。实验室提供学生实践和研究的机会，通过参与无人机及机器人项目，获得实际操作和工程应用的经验。 历年来，我们积极参与各项学科竞赛及科学研究活动，获得若干国家级、省级奖项，成功发表若干SCI、EI论文，项目获得国家级、省级大创立项等。实验室成员毕业后多通过考研、推免升学至复旦大学、厦门大学、华东师范大学、西安电子科技大学等高校，或凭借丰富的工程经验和项目经历成功进入科技公司进行工作。 通过我们的共同努力和研究，在未来将继续前行，书写属于我们的青春华章。 位置: 集美大学克立楼106 - 107 关于本文档 本文档由实验室成员共同开发完善，作为实验室相关项目的开发经验分享和记录，供学弟学妹参考，希望学弟学妹能够在此基础上，传承创新，不断完善，探索属于自己的广阔天地。 "},"00开发者使用手册/":{"url":"00开发者使用手册/","title":"开发者使用手册","keywords":"","body":"开发者使用手册 Author: CGC Date: 2024.11.3 环境依赖 Node & Npm 本项目基于 &color=7cabb1\" alt=\"node\"> 及 &color=66c18c\" alt=\"npm\"> 由于更高的 node 版本可能不支持 gitbook ，经尝试使用 node 版本为 v10，若您版本更高，请降低版本以使用 建议使用node官网安装，一般安装node后npm自动捆绑安装，所以只需要安装node即可 安装成功后，可以使用如下命令验证node和npm安装情况 # 查看node版本 node -v # 查看npm版本 npm -v gitbook 使用如下命令，安装 gitbook 包 npm install -g gitbook-cli 注意： 若前一小节提到的 node 版本过高，这里可能会报错，降级版本即可 文档编辑及修改 请先克隆本项目 git clone https://github.com/BoomBoomFly/BoomBoomFly.github.io.git 文件构成 文件构成及作用大致如下 ├───_book // 构建用于部署的文件夹 │ ├───... ├───assert // 存放外部资源如图片 │ ├───readmeAssert │ ├───imgs │ ├───... ├───node_modules │ ├───... ├───.bookignore ├───book.js // 基本配置文件 ├───package-lock.json ├───package.json ├───README.md // 封面 ├───SUMMARY.md // 用于管理章节 │───... // 章节文章 Easy use: 除了上述有中文注释的部分，其余部分可以理解为对文章书写不重要，只是添加文章可以直接进入文档编辑部分 修改配置 若需要修改例如 书名，logo 等，请在 book.js 中进行对应的修改 文档编辑 修改封面 封面由根目录下的 README.md 文件渲染，修改 README.md 即可修改目录 添加文章 按照 自己喜欢的方式 攥写文章，请使用 markdown 语法，为了项目维护方便，请按照章节创建对应文件夹，例如 00开发者使用手册 ，在里面添加自己的文章，在 assert 文件夹中添加外部依赖文件例如图片 在 SUMMARY.md 添加章节索引（很简单，依葫芦画瓢即可） 插件安装 在添加文章中，可能会涉及到需要添加插件，使用例如如下命令进行插件安装 npm install gitbook-plugin-* 之后，插件包将安装至 node_modules 文件夹中，只需要在 book.js 文件中的 plugins 和 pluginsConfig 插入插件和修改插件配置 本地预览及部署 本地预览 使用 gitbook serve # 或 npm run serve 之后在浏览器中打开 http://localhost:4000 进行本地预览 构建及部署 使用如下命令进行构建 gitbook build # 或 npm run build 之后 将工程push会github仓库 ，即可完成部署， 部署网址为 https://boomboomfly.github.io/ 当然，你需要是组织成员才能进行对应修改，若为实验室新成员还未加入组织，请联系组织管理员~ "},"01常用开发工具/":{"url":"01常用开发工具/","title":"常用开发工具","keywords":"","body":""},"01常用开发工具/git.html":{"url":"01常用开发工具/git.html","title":"git的安装","keywords":"","body":"git的安装 Author: CGC Windows 可在官方网站上下载，网站：https://git-scm.com/ \\ 也可在国内镜像源下载，网站：http://npm.taobao.org/mirrors/git-for-windows Ubuntu sudo apt-get update sudo apt-get upgrade sudo apt-get install git github账号的注册 进入github，注册账号，网站：https://github.com/ 在此处要注意记住你注册时的用户名和邮箱 git的配置 找到git命令行输入处 方法1-Windows 在文件夹中右键，点击 git bash ，没有也没关系，很可能会没有 方法2-Windows 按 win+r 后输入 cmd （在默认路径下呼出）\\ 或 在你的目标文件夹下点击上面的框，输入 cmd 然后回车可以在当前路径下呼出 cmd 方法3-Ubuntu 直接在终端中输入 git 命令即可 配置用户名 在命令行中输入 git config --global user.name \"username\" 此处 username 是自己的用户名 配置邮箱 在命令行中输入 git config --global user.email \"username@email.com\" 此处 username@email.com 是自己的邮箱 验证配置 在命令行中输入 git config --global --list 输出内容可以检查你的配置信息是否争取，如有误可以回到前面的配置步骤进行更改 至此，git下载及配置完成 git常用命令的学习 推荐一个教程网站：https://learngitbranching.js.org/?locale=zh_CN "},"01常用开发工具/conda.html":{"url":"01常用开发工具/conda.html","title":"Conda常用命令","keywords":"","body":"Conda 环境管理及常用指令 Author: CGC 创建环境 conda create -n name python=3.x name为环境名\\ 3.x为指定python版本 删除环境 conda remove -n name --all 激活环境 conda activate name 关闭环境 返回默认环境 conda deactivate name 查看当前有哪些环境 conda info -e 或 conda env list conda包管理 查看当前环境的包 conda list 安装指定package到当前环境 conda install package package 为所需包名字 可在后加入==指定版本或输入url指定安装源 也可以使用pip等进行安装 安装package到指定的环境 conda install -n name package 更新package conda update -n name package 移除package conda remove -n name package 或 conda uninstall package conda版本 更新conda版本 conda update conda 更新python版本 conda update python 假设当前环境是python 3.6 执行命令后conda会将python升级为3.6.x系列的当前最新版本 "},"01常用开发工具/ubuntu换源.html":{"url":"01常用开发工具/ubuntu换源.html","title":"Ubuntu20.04换源","keywords":"","body":"Ubuntu20.04换源 Author: CGC 备份环境变量文件 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak sources.list 即储存环境变量的文件 更换源 sudo vim /etc/apt/sources.list 进入文件后按i或insert启动输入模式 删除原有内容 可在进入输入模式前在航首按dd删除当前行 或dG删除光标以后所有内容 删除内容后使用新源进行替换 阿里源 deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 清华源 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse 中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 网易163源 deb http://mirrors.163.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse 换源完成后 sudo apt-get update sudo apt-get upgrade 让计算机根据源进行更新 "},"02无人机相关/":{"url":"02无人机相关/","title":"无人机相关","keywords":"","body":""},"02无人机相关/ACFly-Mavros.html":{"url":"02无人机相关/ACFly-Mavros.html","title":"ACFly-Mavros的安装及使用","keywords":"","body":"在上位机安装ACFly-Mavros Author: CGC 此为为Jetson配置Intel T265，以此为 Acfly-A9飞控提供定位 官方参考教程：realsense-ros acfly-mavros ROS Wrapper T265使用所需的packages 安装 ROS Install ROS Kinetic on Ubuntu 16.04, ROS Melodic on Ubuntu 18.04, ROS Noetic on Ubuntu 20.04. 可参考autolabor的安装教程 安装realsense2_camera realsense2_camera 可作为 ROS 发行版的 debian 软件包使用 sudo apt-get install ros-$ROS_DISTRO-realsense2-camera 安装mavros sudo apt-get install python-catkin-tools python-rosinstall-generator -y # 如果用的ROS版本是Noetic则使用 # sudo apt install python3-catkin-tools python3-rosinstall-generator python3-osrf-pycommon -y # 需要替换你的ROS版本，且以下指令需要在同一个终端执行 source /opt/ros/${你的ROS版本}/setup.bash # 因为acfly增加了自定义mavlink信息，若之前有通过二进制安装过mavros则需要卸载，没有则跳过 sudo apt purge ros-${ROS_DISTRO}-mavlink ros-${ROS_DISTRO}-mavros # 构建ROS工作空间，可以自行修改路径 mkdir -p ~/acfly_ws/src && cd ~/acfly_ws catkin init # 下载mavlink和acfly-mavros cd src git clone -b release/${ROS_DISTRO}/mavlink/2022.1.5-1 https://gitee.com/LauZanMo/mavlink git clone -b acfly-develop https://gitee.com/LauZanMo/acfly-mavros # 安装依赖，如果rosdep update没执行则需要执行成功才能继续 cd .. && rosdep install --from-paths src --ignore-src -y # 安装GeographicLib: ./src/acfly-mavros/mavros/scripts/install_geographiclib_datasets.sh # 注意此处可能会报需要root权限（不会标error）出现后在前方加sudo即可 # 第一次编译请执行acfly提供的脚本 ./src/acfly-mavros/update_custom_msg.sh # 后续更改mavros源码只需要执行catkin build # 每一次开启终端都需要设置环境变量 source devel/setup.bash 安装T265及相关包 cd ~/acfly_ws/src git clone https://github.com/thien94/vision_to_mavros.git git clone https://github.com/IntelRealSense/librealsense.git cd ~/acfly_ws && catkin build 使用 # 第一个终端 # 打开t265 roslaunch realsense2_camera rs_t265.launch # 第二个终端 # 添加权限 sudo chmod 777 /dev/ttyUSB0 roslaunch mavros acfly.launch fcu_url:=/dev/ttyUSB0:57600 # 第三个终端 # 此处需要先source前一步安装mavros工作空间中的setup.bash source devel/setup.bash roslaunch vision_to_mavros t265_tf_to_mavros.launch 或者单独写一个launch文件 start_all.launch 将文件放在新的ros包 atart_all 中 执行 roslaunch atart_all start_all.launch 请注意\\ roslaunch mavros acfly.launch fcu_url:=/dev/ttyUSB0:57600 中的 fcu_url 请修改为对应 mavlink 输出串口及波特率（也可以直接在launch文件中修改） 其他 使用指南 acfly-mavros 作者提供了使用指南及二次开发指南\\ 使用指南二次开发指南 "},"02无人机相关/T265.html":{"url":"02无人机相关/T265.html","title":"T265的基本使用","keywords":"","body":"关于T265的使用 Author: CGC 硬件参数 T265采用了Movidius Myriad 2视觉处理单元（VPU），V-SLAM算法都直接在VPU上运行 可直接输出6DOF相机位姿 使用双目鱼眼相机 分辨率848X800分辨率 30HZ 单色图像 视场角 163° Fov(±5°) IMU型号为 BMI-055SDK 从 Intel® RealSense™ SDK 2.0 (v2.54.1) 中已经明确说明版本不再支持T265 最后一个支持的版本为 v2.50.0，而期间的几个版本虽然支持T265但官方说明不在对其进行测试。安装方式 其中一种方式，测试可用 ```bash mkdir ~/releases-2.50.0 cd ~/releases-2.50.0 克隆仓库并进入分支 git clone https://github.com/IntelRealSense/realsense-ros.git cd realsense-ros/ git checkout git tag | sort -V | grep -P \"^2.\\d+\\.\\d+\" | tail -1 也可以直接进入仓库下载源码 编译 mkdir build cd build cmake .. make make install ### SDK启动 ```bash realsense-viewer Realsense2 此库为双目提供驱动，包括 T265 D400系列等 安装 sudo apt-get install ros-$ROS_DISTRO-realsense2-camera 一般情况下，安装后库会存在于 /opt/ros/noetic/share/realsense2_camera (与ros安装路径有关) 也可以通过源码安装，放置在自己工作空间下 部分常用launch 启动T265 roslaunch realsense2_camera rs_t265.launch 同时启动T265和D400系列 roslaunch realsense2_camera rs_d400_and_t265.launch 通过话题获取数据 话题 以使用 roslaunch realsense2_camera rs_t265.launch 开启T265为例，使用 rostopic 查看话题，能够得到以下话题 /camera/accel/imu_info /camera/accel/metadata /camera/accel/sample /camera/gyro/imu_info /camera/gyro/metadata /camera/gyro/sample /camera/odom/metadata /camera/odom/sample /camera/realsense2_camera_manager/bond /camera/tracking_module/parameter_descriptions /camera/tracking_module/parameter_updates /diagnostics /tf /tf_static 常用的有\\ 里程计发布 /camera/odom/sample IMU发布\\ 陀螺仪 /camera/accel/sample 200Hz\\ 加速度 /camera/gyro/sample 63Hz 里程计信息demo 可以通过订阅 /camera/odom/sample 话题，输出里程坐标\\ 其输出坐标系信息为：正前方为X轴正方向、左边为Y轴正方向、天向为Z轴正方向 即FLU\\ 输出频率为 200Hz CPP #include #include void poseCallback(const nav_msgs::Odometry::ConstPtr& msg) { geometry_msgs::Point position = msg->pose.pose.position; geometry_msgs::Quaternion orientation = msg->pose.pose.orientation; // 打印位置和姿态信息 ROS_INFO(\"位置 X: %f\", position.x); ROS_INFO(\"位置 Y: %f\", position.y); ROS_INFO(\"位置 Z: %f\", position.z); ROS_INFO(\"姿态 W: %f\", orientation.w); ROS_INFO(\"姿态 X: %f\", orientation.x); ROS_INFO(\"姿态 Y: %f\", orientation.y); ROS_INFO(\"姿态 Z: %f\", orientation.z); ROS_INFO(\"----------------------------------\"); } int main(int argc, char** argv) { setlocale(LC_ALL,\"\"); // 初始化 ROS 节点 ros::init(argc, argv, \"t265_motion_subscriber\"); // 创建一个节点句柄 ros::NodeHandle nh; // 创建一个订阅者，订阅 T265 相机的姿态数据 ros::Subscriber sub = nh.subscribe(\"/camera/odom/sample\", 10, poseCallback); // 进入 ROS 循环 ros::spin(); return 0; } Python import rospy from nav_msgs.msg import Odometry import time def pose_callback(msg: Odometry): position = msg.pose.pose.position orientation = msg.pose.pose.orientation # 打印位置和姿态信息 rospy.loginfo(\"位置 X: %f\", position.x) rospy.loginfo(\"位置 Y: %f\", position.y) rospy.loginfo(\"位置 Z: %f\", position.z) rospy.loginfo(\"姿态 W: %f\", orientation.w) rospy.loginfo(\"姿态 X: %f\", orientation.x) rospy.loginfo(\"姿态 Y: %f\", orientation.y) rospy.loginfo(\"姿态 Z: %f\", orientation.z) rospy.loginfo(\"----------------------------------\") time.sleep(1) def main(): # 初始化 ROS 节点 rospy.init_node(\"t265_motion_subscriber\") # 创建一个订阅者，订阅 T265 相机的姿态数据 rospy.Subscriber(\"/camera/odom/sample\", Odometry, pose_callback) # 进入 ROS 循环 rospy.spin() if __name__ == '__main__': main() 注意事项 T265等需要在计算机开机后插入或使用代码进行刷新，否则将无法被识别 "},"02无人机相关/UWB.html":{"url":"02无人机相关/UWB.html","title":"UWB的使用","keywords":"","body":"UWB的使用 Author: CGC 使用 Nooploop 的 LinkTrack 定位系统为 Acfly飞控提供定位 官方资料 配置 我们使用的是4基站+1标签+1控制台的方案 参考的是官方用户手册中第13-14页的内容 按顺序0-3的id分别配置4个anchor 配置tag标签（飞控端） 通信协议选择tag_frame0 配置console控制台 摆放及上电方向 由于飞控的数据适配性，基站摆放位置和飞机上电位置需要受到限制\\ （可能之后随着设备的更新会减轻这方面带来的影响，但是按我们目前的测试结果来看，还是非常建议按照已经测试好的方向进行初始化） 如下 飞控通信协议设置 tag端通信协议 具体通信协议可以参考官方参考通信协议 在此处对飞控段使用的协议即 Tag 端作说明 即 tag端通信协议（接收）如下 可知飞控可接收到数据有位置、姿态、精度等一系列数据 官方驱动代码 以下给出acfly官方发布的驱动代码 #include \"drv_UWB_LinkTrack.hpp\" #include \"Commulink.hpp\" #include \"Basic.hpp\" #include \"FreeRTOS.h\" #include \"task.h\" #include \"SensorsBackend.hpp\" #include \"MeasurementSystem.hpp\" struct DriverInfo { uint32_t param; Port port; uint32_t sensor_key; }; typedef struct { uint8_t id; uint8_t role; int pos_x:24; int pos_y:24; int pos_z:24; int vel_x:24; int vel_y:24; int vel_z:24; int dis_0:24; int dis_1:24; int dis_2:24; int dis_3:24; int dis_4:24; int dis_5:24; int dis_6:24; int dis_7:24; float imuGyro[3]; float imuAcc[3]; uint8_t reserved1[12]; int16_t angle[3]; float q[4]; uint8_t reserved2[4]; uint32_t localTime; uint32_t systemTime; uint8_t reserved3[1]; uint8_t eop[3]; // 估计位置的精度 uint16_t voltage; uint8_t reserved4[5]; }__PACKED _Uwb; static const unsigned char packet_ID[2] = { 0x55 , 0x01 }; static void OpticalFlow_Server(void* pvParameters) { DriverInfo driver_info = *(DriverInfo*)pvParameters; delete (DriverInfo*)pvParameters; /*状态机*/ _Uwb Uwb; unsigned char rc_counter = 0; signed char sum = 0; /*状态机*/ //等待初始化完成 while( get_Altitude_MSStatus() != MS_Ready ) os_delay(1); //注册传感器 double angleOffset = 0; if( driver_info.param>360 ) { //记录初始偏航 Quaternion quat; get_Attitude_quat(&quat); angleOffset = quat.getYaw(); } else angleOffset = degree2rad((double)driver_info.param); uint32_t sensor_key = PositionSlamSensorRegister( default_uwb_sensor_index , \\ \"UWB_LinkTrack\" ,\\ Position_Sensor_Type_RelativePositioning , \\ Position_Sensor_DataType_s_xy , \\ Position_Sensor_frame_SLAM , \\ 0.1, angleOffset, 100 ); int lastP = 0; uint8_t pUCCounter = 0; while(1) { uint8_t rdata; if( driver_info.port.read( &rdata, 1, 2, 0.5 ) ) { if( rc_counter 200 || Uwb.eop[1]>200 ) // x y 精度大于2cm就失能 PositionSensorSetInavailable(default_uwb_sensor_index,driver_info.sensor_key); else { vector3 pos, vel; pos.x = Uwb.pos_x*0.1; pos.y = Uwb.pos_y*0.1; pos.z = Uwb.pos_z * 0.1; vel.x = Uwb.vel_x*0.01; vel.y = Uwb.vel_y*0.01; vel.z = Uwb.vel_z * 0.01; if( Uwb.eop[2] > 200 ) PositionSensorChangeDataType( default_uwb_sensor_index,sensor_key, Position_Sensor_DataType_s_xy ); else PositionSensorChangeDataType( default_uwb_sensor_index,sensor_key, Position_Sensor_DataType_s_xyz ); double eop_xy = sqrtf( Uwb.eop[0]*Uwb.eop[0] + Uwb.eop[1]*Uwb.eop[1] ); if( Uwb.dis_0 != lastP ) { lastP = Uwb.dis_0; pUCCounter = 0; } else { if( pUCCounter 100 ) PositionSensorSetInavailable( default_uwb_sensor_index,sensor_key ); else PositionSensorUpdatePosition( default_uwb_sensor_index,sensor_key, pos, true, -1, eop_xyparam = param; driver_info->port = port; xTaskCreate( OpticalFlow_Server, \"OptFlowGL9306\", 1024, (void*)driver_info, SysPriority_ExtSensor, NULL); return true; } void init_drv_UWB_LinkTrack() { PortFunc_Register( 41, UWB_LinkTrack_DriverInit ); } 值得一提 在以上驱动代码中，值得一提的是 // z 精度大于2cm就不使用z轴数据 if( Uwb.eop[2] > 200 ) PositionSensorChangeDataType( default_uwb_sensor_index,sensor_key, Position_Sensor_DataType_s_xy ); else PositionSensorChangeDataType( default_uwb_sensor_index,sensor_key, Position_Sensor_DataType_s_xyz ); 及 if( Uwb.eop[0]>200 || Uwb.eop[1]>200 ) // x y 精度大于2cm就失能 PositionSensorSetInavailable(default_uwb_sensor_index,driver_info.sensor_key); else { // ... } 驱动内容为 超出2cm的精度许可范围，就将传感器失能\\ UWB官方给出的数据是，x y 的精度在 10cm 之内 z 精度在 30cm 以内 关于z轴数据\\ 这样一来其实可以反应我们看到的现象，首先是在只使用uwb作为外接传感器时，飞机完全定不住高（因为z精度完全无法满足2cm的要求），但是可能由于飞控中气压计等设备的存在，飞控有高度数据，室内定位可用，所以能够允许起飞，但在天上的高度数据，完全由飞控而来，所以现象是，没有定高可言。。。 注意事项及传感器使用建议 使用时发起自动标定的设备需要在线，比如我们使用控制台发起一键标定，则在使用时控制台必须要在线，否则数据会不可用 由于uwb的z轴精度较低，建议加上tfmini等作为定高传感器，通过测试，有uwb加上tfmini，定位效果较好 写在最后 通过这段时间的测试，我们发现至少在电赛赛制的背景下，用uwb可能会出现某些限制，比如场地不一定能够容纳摆放下基站，并且无法在换场地后进行标定，可能受到干扰等 对于电赛（赛场不允许携带笔记本及pc，上位机只支持x86，我们手上已有的板载电脑皆为arm，无法在现场进行标定）无法在换场地后进行标定的情况，可能考虑自行写接口，使用单片机或板载电脑进行标定，能够很大程度减少对位置场地的限制，我们尝试按照通信协议写了一份一键自动标定的程序，但还未在实际场地中进行测试。 "},"02无人机相关/D435.html":{"url":"02无人机相关/D435.html","title":"D435的基本使用","keywords":"","body":"D435的基本使用 Author: CGC 相机基础使用 配置RealSense深度相机 # 配置RealSense深度相机 pipeline = rs.pipeline() config = rs.config() config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) config.enable_stream(rs.stream.color, 640, 480, rs.format.rgb8, 30) # 启动深度和RGB流 pipeline.start(config) 获取RGB图像和深度图像 # 等待帧 frames = pipeline.wait_for_frames() depth_frame = frames.get_depth_frame() color_frame = frames.get_color_frame() # 将深度图像和RGB图像转换为numpy数组 depth_image = np.asanyarray(depth_frame.get_data()) color_image = np.asanyarray(color_frame.get_data()) # 转化图像空间 color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB) 输出图像 # 输出图像 cv2.imshow(\"color_image\", color_image) cv2.imshow(\"depth_image\", depth_image) cv2.waitKey(1) D435+Yolov5 import cv2 from loguru import logger import numpy as np from pyzbar import pyzbar import pyrealsense2 as rs import pytesseract import torch import sys import json import math def detect_obj_yolov5(depth_image, color_image, detect_target: str = None, model = None, show = 0): if model is not None: results = model(color_image) # 将结果转为json数据 json_data = results.pandas().xyxy[0].to_json(orient=\"records\") # 解析 JSON 数据 target_x = 0 target_y = 0 depth = 0 try: data = json.loads(json_data) for d in data: # 匹配目标 if d.get('name') == detect_target and all(key in d for key in ('xmin', 'xmax', 'ymin', 'ymax')): target_x = int((d['xmin'] + d['xmax']) / 2) target_y = int((d['ymin'] + d['ymax']) / 2) color_image = results.render()[0] depth = depth_image[target_y, target_x] break else: target_x = 0 target_y = 0 depth = 0 except: target_x = 0 target_y = 0 depth = 0 logger.info('{}, {}, depth: {}'.format(int(target_x), int(target_y), depth)) if show: cv2.imshow(\"detect_obj_yolov5\", color_image) cv2.waitKey(1) if __name__ == \"__main__\": path1 = '/home/c/Library/Cv_for_Orinnano/detection_module' path2 = '/home/c/Library/Cv_for_Orinnano/detection_module/models/yolov5n.pt' # model_land = torch.hub.load(path1, 'custom', path2_land, source='local', device = 0, force_reload = True) # 不用的话注释掉提高启动效率 model = torch.hub.load(path1, 'custom', path2, source='local', device = 0, force_reload = True) # 不用的话注释掉提高启动效率 # 配置RealSense深度相机 pipeline = rs.pipeline() config = rs.config() config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30) config.enable_stream(rs.stream.color, 640, 480, rs.format.rgb8, 30) # 启动深度和RGB流 pipeline.start(config) while True: # 等待帧 frames = pipeline.wait_for_frames() depth_frame = frames.get_depth_frame() color_frame = frames.get_color_frame() # 将深度图像和RGB图像转换为numpy数组 depth_image = np.asanyarray(depth_frame.get_data()) color_image = np.asanyarray(color_frame.get_data()) # 转化图像空间 color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB) detect_obj_yolov5(depth_image, color_image, detect_target = 'person', model = model, show = 1) "}}